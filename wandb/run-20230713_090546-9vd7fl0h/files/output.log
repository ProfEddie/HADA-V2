Trainable Paras: 9988097
TRAIN FROM SCRATCH
0.0
  0%|                                                                   | 0/100 [00:00<?, ?it/s]
  0%|                                                        | 1/3625 [00:03<3:19:29,  3.30s/it]

  0%|                                                        | 2/3625 [00:05<2:52:06,  2.85s/it]

  0%|                                                        | 3/3625 [00:08<2:43:16,  2.70s/it]

  0%|                                                        | 4/3625 [00:10<2:38:57,  2.63s/it]
  offset = -low * scale                                      | 4/3625 [00:10<2:38:57,  2.63s/it]
  0%|                                                        | 5/3625 [00:13<2:36:52,  2.60s/it]

  0%|                                                        | 6/3625 [00:15<2:35:56,  2.59s/it]

  0%|                                                        | 7/3625 [00:18<2:35:51,  2.58s/it]

  offset = -low * scale                                      | 8/3625 [00:21<2:35:06,  2.57s/it]
  0%|▏                                                       | 9/3625 [00:23<2:34:29,  2.56s/it]
0.002206896551724138

  0%|▏                                                      | 10/3625 [00:26<2:34:03,  2.56s/it]

  0%|▏                                                      | 11/3625 [00:28<2:34:23,  2.56s/it]

  0%|▏                                                      | 12/3625 [00:31<2:33:27,  2.55s/it]

  0%|▏                                                      | 13/3625 [00:33<2:33:31,  2.55s/it]

  0%|▏                                                      | 14/3625 [00:36<2:32:39,  2.54s/it]

  0%|▏                                                      | 15/3625 [00:38<2:32:00,  2.53s/it]

  0%|▏                                                      | 16/3625 [00:41<2:31:29,  2.52s/it]

  0%|▎                                                      | 17/3625 [00:43<2:30:53,  2.51s/it]

  0%|▎                                                      | 18/3625 [00:46<2:31:14,  2.52s/it]

  1%|▎                                                      | 19/3625 [00:48<2:31:27,  2.52s/it]

  1%|▎                                                      | 20/3625 [00:51<2:31:39,  2.52s/it]

  1%|▎                                                      | 21/3625 [00:53<2:32:10,  2.53s/it]

  1%|▎                                                      | 22/3625 [00:56<2:32:50,  2.55s/it]


  1%|▎                                                      | 24/3625 [01:01<2:32:32,  2.54s/it]
0.006344827586206896

  1%|▍                                                      | 25/3625 [01:04<2:31:55,  2.53s/it]

  1%|▍                                                      | 26/3625 [01:06<2:31:37,  2.53s/it]


  1%|▍                                                      | 28/3625 [01:11<2:31:22,  2.53s/it]
0.0074482758620689656

  1%|▍                                                      | 29/3625 [01:14<2:31:16,  2.52s/it]

  1%|▍                                                      | 30/3625 [01:16<2:31:22,  2.53s/it]

  1%|▍                                                      | 31/3625 [01:19<2:31:03,  2.52s/it]

  1%|▍                                                      | 32/3625 [01:21<2:31:09,  2.52s/it]

  1%|▌                                                      | 33/3625 [01:24<2:30:59,  2.52s/it]

  1%|▌                                                      | 34/3625 [01:26<2:31:21,  2.53s/it]

  1%|▌                                                      | 35/3625 [01:29<2:31:45,  2.54s/it]

  1%|▌                                                      | 36/3625 [01:31<2:31:09,  2.53s/it]

  1%|▌                                                      | 37/3625 [01:34<2:30:51,  2.52s/it]

  1%|▌                                                      | 38/3625 [01:36<2:30:58,  2.53s/it]

  1%|▌                                                      | 39/3625 [01:39<2:31:10,  2.53s/it]

  1%|▌                                                      | 40/3625 [01:42<2:30:39,  2.52s/it]

  1%|▌                                                      | 41/3625 [01:44<2:30:50,  2.53s/it]

  1%|▋                                                      | 42/3625 [01:47<2:30:18,  2.52s/it]

  1%|▋                                                      | 43/3625 [01:49<2:29:46,  2.51s/it]

  1%|▋                                                      | 44/3625 [01:52<2:29:46,  2.51s/it]

  1%|▋                                                      | 45/3625 [01:54<2:29:42,  2.51s/it]


  1%|▋                                                      | 47/3625 [01:59<2:30:57,  2.53s/it]
0.012689655172413793

  1%|▋                                                      | 48/3625 [02:02<2:30:49,  2.53s/it]

  1%|▋                                                      | 49/3625 [02:04<2:30:54,  2.53s/it]

  1%|▊                                                      | 50/3625 [02:07<2:30:55,  2.53s/it]

  1%|▊                                                      | 51/3625 [02:09<2:31:16,  2.54s/it]

  1%|▊                                                      | 52/3625 [02:12<2:31:24,  2.54s/it]

  1%|▊                                                      | 53/3625 [02:14<2:31:45,  2.55s/it]

Traceback (most recent call last):                          | 54/3625 [02:17<2:33:11,  2.57s/it]
  File "/home/nmduy/HADA/chau/HADA-LAVIS/main.py", line 126, in <module>
    run_train(args)
  File "/home/nmduy/HADA/chau/HADA-LAVIS/main.py", line 72, in run_train
    controller.train(dataset_train=train_dataset,  dataset_val=val_dataset,
  File "/home/nmduy/HADA/chau/HADA-LAVIS/Controller.py", line 456, in train
    loss_tr_dict = self.train_epoch(dataloader_train, idx_epoch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nmduy/HADA/chau/HADA-LAVIS/Controller.py", line 319, in train_epoch
    for idx, batch in enumerate(dataloader):
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/nmduy/HADA/chau/HADA-LAVIS/Utils.py", line 237, in __getitem__
    image_input_1 = self.vis_processors_1[self.type_dataset](image_raw).unsqueeze(0).to(self.device) if image_raw is not None else None
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nmduy/HADA/chau/HADA-LAVIS/LAVIS/lavis/processors/blip_processors.py", line 142, in __call__
    return self.transform(item)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
           ^^^^^^^^^^^^^^^^
  File "/home/jarvis/anaconda3/envs/hada-v2/lib/python3.11/site-packages/torchvision/transforms/functional.py", line 155, in to_tensor
    return img.to(dtype=default_float_dtype).div(255)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt